{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0510697e-8892-47bf-8ce0-a2a581ea86af",
   "metadata": {},
   "source": [
    "### 1. Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700f0c9-e6aa-48c1-a85a-b509b7390cbd",
   "metadata": {},
   "source": [
    "#### Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4aa204b-a480-4821-9852-88c12aa8d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = load_breast_cancer()\n",
    "x = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b18e0601-6e45-4225-9f94-c1a294bbc92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
      "0                   0.07871  ...        25.380          17.33   \n",
      "1                   0.05667  ...        24.990          23.41   \n",
      "2                   0.05999  ...        23.570          25.53   \n",
      "3                   0.09744  ...        14.910          26.50   \n",
      "4                   0.05883  ...        22.540          16.67   \n",
      "..                      ...  ...           ...            ...   \n",
      "564                 0.05623  ...        25.450          26.40   \n",
      "565                 0.05533  ...        23.690          38.25   \n",
      "566                 0.05648  ...        18.980          34.12   \n",
      "567                 0.07016  ...        25.740          39.42   \n",
      "568                 0.05884  ...         9.456          30.37   \n",
      "\n",
      "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
      "0             184.60      2019.0           0.16220            0.66560   \n",
      "1             158.80      1956.0           0.12380            0.18660   \n",
      "2             152.50      1709.0           0.14440            0.42450   \n",
      "3              98.87       567.7           0.20980            0.86630   \n",
      "4             152.20      1575.0           0.13740            0.20500   \n",
      "..               ...         ...               ...                ...   \n",
      "564           166.10      2027.0           0.14100            0.21130   \n",
      "565           155.00      1731.0           0.11660            0.19220   \n",
      "566           126.70      1124.0           0.11390            0.30940   \n",
      "567           184.60      1821.0           0.16500            0.86810   \n",
      "568            59.16       268.6           0.08996            0.06444   \n",
      "\n",
      "     worst concavity  worst concave points  worst symmetry  \\\n",
      "0             0.7119                0.2654          0.4601   \n",
      "1             0.2416                0.1860          0.2750   \n",
      "2             0.4504                0.2430          0.3613   \n",
      "3             0.6869                0.2575          0.6638   \n",
      "4             0.4000                0.1625          0.2364   \n",
      "..               ...                   ...             ...   \n",
      "564           0.4107                0.2216          0.2060   \n",
      "565           0.3215                0.1628          0.2572   \n",
      "566           0.3403                0.1418          0.2218   \n",
      "567           0.9387                0.2650          0.4087   \n",
      "568           0.0000                0.0000          0.2871   \n",
      "\n",
      "     worst fractal dimension  \n",
      "0                    0.11890  \n",
      "1                    0.08902  \n",
      "2                    0.08758  \n",
      "3                    0.17300  \n",
      "4                    0.07678  \n",
      "..                       ...  \n",
      "564                  0.07115  \n",
      "565                  0.06637  \n",
      "566                  0.07820  \n",
      "567                  0.12400  \n",
      "568                  0.07039  \n",
      "\n",
      "[569 rows x 30 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "564    0\n",
      "565    0\n",
      "566    0\n",
      "567    0\n",
      "568    1\n",
      "Name: target, Length: 569, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbd9717-ee5f-4f13-bf7c-4afe8d0bd135",
   "metadata": {},
   "source": [
    "#### Step 2: Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3b4dfe3-aba7-46cc-8e07-995a892bc133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(x.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8777f65c-cbfd-4840-ac0f-5697e1ef6cba",
   "metadata": {},
   "source": [
    "#### Step 3: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6c4aeb4-d5b8-4819-b8c7-68c6c88bad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "X_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2cfd97e3-5468-439f-abfd-3e4cd3feceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.09706398 -2.07333501  1.26993369 ...  2.29607613  2.75062224\n",
      "   1.93701461]\n",
      " [ 1.82982061 -0.35363241  1.68595471 ...  1.0870843  -0.24388967\n",
      "   0.28118999]\n",
      " [ 1.57988811  0.45618695  1.56650313 ...  1.95500035  1.152255\n",
      "   0.20139121]\n",
      " ...\n",
      " [ 0.70228425  2.0455738   0.67267578 ...  0.41406869 -1.10454895\n",
      "  -0.31840916]\n",
      " [ 1.83834103  2.33645719  1.98252415 ...  2.28998549  1.91908301\n",
      "   2.21963528]\n",
      " [-1.80840125  1.22179204 -1.81438851 ... -1.74506282 -0.04813821\n",
      "  -0.75120669]]\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e26edf-9197-42d8-a5ea-84efb1a1c9ff",
   "metadata": {},
   "source": [
    "StandardScaler standardizes features by removing the mean and scaling to unit variance, which is appropriate here because most features are continuous and measured on different scales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17402a-fef2-404b-bb00-11adfc99b3c4",
   "metadata": {},
   "source": [
    "### 2. Classification Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "419ab02d-11d0-4164-bd17-c4b931dcc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23fdee0-86c0-4fe0-8540-543b18cf3787",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "408037bc-3f3d-402d-90a4-8eb4855b8f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a128b3-7f50-4bf8-b74d-e47e321d7b9a",
   "metadata": {},
   "source": [
    "**How it works:**\n",
    "* Logistic Regression models the probability that a sample belongs to a particular class using a sigmoid function.\n",
    "* It's best for linearly separable data.\n",
    "\n",
    "**Why it's suitable:**\n",
    "* Breast cancer data has features that often separate benign from malignant tumors linearly.\n",
    "* It's interpretable and fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6338bd-de93-43b8-97e9-6445e1f4ddcc",
   "metadata": {},
   "source": [
    "#### 2. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9eeeccfa-0b62-486b-8df6-94f5d36fd111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d90731a-9a54-4538-a084-dc6bd4aef56c",
   "metadata": {},
   "source": [
    "**How it works:**\n",
    "\n",
    "* Decision Trees split data based on feature thresholds, creating a tree-like structure.\n",
    "* Each leaf represents a class label.\n",
    "\n",
    "**Why it's suitable:**\n",
    "* Captures non-linear relationships and is easy to interpret.\n",
    "* Handles both numerical and categorical data (though we only have numerical here)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed7c96-fb2c-4b24-af85-45a72de38c8b",
   "metadata": {},
   "source": [
    "#### 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "03a5f0f5-3a6f-450e-9f38-62e2afbcc164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe64fec-74c5-465d-ab50-0921f8c512db",
   "metadata": {},
   "source": [
    "**How it works:**\n",
    "* An ensemble of decision trees using bootstrapped datasets and feature randomness to improve generalization.\n",
    "\n",
    "**Why it's suitable:**\n",
    "* Reduces overfitting common in single decision trees.\n",
    "* Works well with high-dimensional data like this dataset (30 features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b56b42-20e8-480c-b5cc-681b142feda3",
   "metadata": {},
   "source": [
    "#### 4. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d8c4912a-efc2-4287-8086-2556f51e1c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d84b3-1b8b-4451-9b8d-24edd73bffee",
   "metadata": {},
   "source": [
    "**How it works:**\n",
    "* SVM finds the optimal hyperplane that maximizes the margin between classes.\n",
    "* Can use kernels for non-linear classification.\n",
    "\n",
    "**Why it's suitable:**\n",
    "* Very effective in high-dimensional spaces.\n",
    "* Robust in cases where the number of features > number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a4f11c-d3ec-4ed6-9f27-89a9e25f2510",
   "metadata": {},
   "source": [
    "#### 5. k-Nearest Neighbors (k-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1049bcb2-02ed-4165-8b4d-5a3dae3068b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassification Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"KNeighborsClassification Accuracy:\", accuracy_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d852816-fa0c-442f-ace5-1b1725265a95",
   "metadata": {},
   "source": [
    "**How it works:** \n",
    "* k-NN classifies new samples based on the majority label of their k nearest neighbors in the feature space.\n",
    "\n",
    "**Why it's suitable:** \n",
    "* Simple and effective for smaller datasets like breast cancer (569 samples).\n",
    "* Works well when data is well-separated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4105d6-0a4e-4005-98d1-e05f41bd8169",
   "metadata": {},
   "source": [
    "### 3. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8b3d977f-6e43-4327-8389-c3fdeb7f4083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.95      0.96        43\n",
      "      benign       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[41  2]\n",
      " [ 1 70]]\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.93      0.93        43\n",
      "      benign       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40  3]\n",
      " [ 3 68]]\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.93      0.95        43\n",
      "      benign       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40  3]\n",
      " [ 1 70]]\n",
      "\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.95      0.96        43\n",
      "      benign       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[41  2]\n",
      " [ 1 70]]\n",
      "\n",
      "k-NN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.93      0.93        43\n",
      "      benign       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40  3]\n",
      " [ 3 68]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "models = {\n",
    "    'Logistic Regression': y_pred_lr,\n",
    "    'Decision Tree': y_pred_dt,\n",
    "    'Random Forest': y_pred_rf,\n",
    "    'SVM': y_pred_svm,\n",
    "    'k-NN': y_pred_knn\n",
    "}\n",
    "\n",
    "for name, y_pred in models.items():\n",
    "    print(f\"\\n{name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=data.target_names))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21514d0e-1347-4ed0-afc8-24eb0bf9476c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
