{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02475ad5-c15e-4276-a27b-26951bcfc148",
   "metadata": {},
   "source": [
    "#### 1. Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15253819-0cbd-4587-a827-96a5c4af0bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 20640\n",
      "\n",
      ":Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      ":Attribute Information:\n",
      "    - MedInc        median income in block group\n",
      "    - HouseAge      median house age in block group\n",
      "    - AveRooms      average number of rooms per household\n",
      "    - AveBedrms     average number of bedrooms per household\n",
      "    - Population    block group population\n",
      "    - AveOccup      average number of household members\n",
      "    - Latitude      block group latitude\n",
      "    - Longitude     block group longitude\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. rubric:: References\n",
      "\n",
      "- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "  Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Optional: view feature names and description\n",
    "print(housing.feature_names)\n",
    "print(housing.DESCR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caa2b094-45b8-4879-b12e-e10023cf3d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  MedHouseVal  \n",
      "0    -122.23        4.526  \n",
      "1    -122.22        3.585  \n",
      "2    -122.24        3.521  \n",
      "3    -122.25        3.413  \n",
      "4    -122.25        3.422  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "\n",
    "# Add the target variable to the DataFrame\n",
    "df['MedHouseVal'] = housing.target\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94a623f8-b3f5-4ec4-a810-b829c279ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedInc         20640\n",
      "HouseAge       20640\n",
      "AveRooms       20640\n",
      "AveBedrms      20640\n",
      "Population     20640\n",
      "AveOccup       20640\n",
      "Latitude       20640\n",
      "Longitude      20640\n",
      "MedHouseVal    20640\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nulvalues = df.isnull().count()\n",
    "print(nulvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5e58b19-3efb-4183-aa03-1249b1364255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " MedInc         0\n",
      "HouseAge       0\n",
      "AveRooms       0\n",
      "AveBedrms      0\n",
      "Population     0\n",
      "AveOccup       0\n",
      "Latitude       0\n",
      "Longitude      0\n",
      "MedHouseVal    0\n",
      "dtype: int64\n",
      "     MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  2.344766  0.982143  0.628559  -0.153758   -0.974429 -0.049597  1.052548   \n",
      "1  2.332238 -0.607019  0.327041  -0.263336    0.861439 -0.092512  1.043185   \n",
      "2  1.782699  1.856182  1.155620  -0.049016   -0.820777 -0.025843  1.038503   \n",
      "3  0.932968  1.856182  0.156966  -0.049833   -0.766028 -0.050329  1.038503   \n",
      "4 -0.012881  1.856182  0.344711  -0.032906   -0.759847 -0.085616  1.038503   \n",
      "\n",
      "   Longitude  \n",
      "0  -1.327835  \n",
      "1  -1.322844  \n",
      "2  -1.332827  \n",
      "3  -1.337818  \n",
      "4  -1.337818  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Check for missing values\n",
    "missing_counts = df.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_counts)\n",
    "\n",
    "# Handle missing values if any (not expected, but included for completeness)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('MedHouseVal', axis=1)\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert scaled data back to DataFrame (optional)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Show a preview of the scaled features\n",
    "print(X_scaled_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790d8210-b7fb-4128-a243-bb250c458d0f",
   "metadata": {},
   "source": [
    "##### 1. Conversion to a Pandas DataFrame\n",
    "A DataFrame provides easier handling for data manipulation, visualization, and inspection, such as checking for missing values or generating summary statistics.\n",
    "\n",
    "##### 2. Handling Missing Values\n",
    "Machine learning models generally cannot handle missing values. Although the California Housing dataset does not have missing values by default, it is good practice to check. Filling missing values with the mean is a common, simple imputation method for numerical data.\n",
    "\n",
    "##### 3. Feature Scaling (Standardization)\n",
    "Standardization ensures all features contribute equally to the learning process.\n",
    "\n",
    "These preprocessing steps help ensure the dataset is clean, uniform, and suitable for training accurate and reliable machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66221848-8486-43ce-8a10-f0185ab427d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. Regression Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8fa290-7532-483a-8277-62ce0b48f4b1",
   "metadata": {},
   "source": [
    "#### 1. Linear Regression\n",
    "\n",
    "Linear Regression models the relationship between the independent variables and the target by fitting a straight line (or hyperplane in higher dimensions) that minimizes the sum of squared differences between predicted and actual values.\n",
    "\n",
    "##### Suitability:\n",
    "    a. Works well when the relationship between features and target is approximately linear.\n",
    "    b. Fast and interpretable baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "450ffd65-b2f6-49f9-938e-69289b877f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCALED VALUES:  [[ 2.34476576  0.98214266  0.62855945 ... -0.04959654  1.05254828\n",
      "  -1.32783522]\n",
      " [ 2.33223796 -0.60701891  0.32704136 ... -0.09251223  1.04318455\n",
      "  -1.32284391]\n",
      " [ 1.7826994   1.85618152  1.15562047 ... -0.02584253  1.03850269\n",
      "  -1.33282653]\n",
      " ...\n",
      " [-1.14259331 -0.92485123 -0.09031802 ... -0.0717345   1.77823747\n",
      "  -0.8237132 ]\n",
      " [-1.05458292 -0.84539315 -0.04021111 ... -0.09122515  1.77823747\n",
      "  -0.87362627]\n",
      " [-0.78012947 -1.00430931 -0.07044252 ... -0.04368215  1.75014627\n",
      "  -0.83369581]]\n",
      "\n",
      "\n",
      "TARGET VALUES:  0        4.526\n",
      "1        3.585\n",
      "2        3.521\n",
      "3        3.413\n",
      "4        3.422\n",
      "         ...  \n",
      "20635    0.781\n",
      "20636    0.771\n",
      "20637    0.923\n",
      "20638    0.847\n",
      "20639    0.894\n",
      "Name: MedHouseVal, Length: 20640, dtype: float64\n",
      "\n",
      "\n",
      "PREDICATED VALUES:  [4.13164983 3.97660644 3.67657094 ... 0.17125141 0.31910524 0.51580363]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_scaled, y)\n",
    "lr_preds = lr_model.predict(X_scaled)\n",
    "\n",
    "print(\"SCALED VALUES: \", X_scaled) \n",
    "print(\"\\n\")\n",
    "print(\"TARGET VALUES: \", y)\n",
    "print(\"\\n\")\n",
    "print(\"PREDICATED VALUES: \", lr_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e03c6f1-adaf-42e9-a7c1-beb7e1eb5e55",
   "metadata": {},
   "source": [
    "#### 2. Decision Tree Regressor\n",
    "Decision Trees split the data into regions by asking a series of \"if-else\" questions on feature values, minimizing the error in each leaf.\n",
    "\n",
    "##### Suitability:\n",
    "    a. Captures non-linear relationships and interactions between features.\n",
    "    b. Easy to interpret, though prone to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "429f6697-dd51-41b1-87ab-73789cbcaa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCALED VALUES:  [[ 2.34476576  0.98214266  0.62855945 ... -0.04959654  1.05254828\n",
      "  -1.32783522]\n",
      " [ 2.33223796 -0.60701891  0.32704136 ... -0.09251223  1.04318455\n",
      "  -1.32284391]\n",
      " [ 1.7826994   1.85618152  1.15562047 ... -0.02584253  1.03850269\n",
      "  -1.33282653]\n",
      " ...\n",
      " [-1.14259331 -0.92485123 -0.09031802 ... -0.0717345   1.77823747\n",
      "  -0.8237132 ]\n",
      " [-1.05458292 -0.84539315 -0.04021111 ... -0.09122515  1.77823747\n",
      "  -0.87362627]\n",
      " [-0.78012947 -1.00430931 -0.07044252 ... -0.04368215  1.75014627\n",
      "  -0.83369581]]\n",
      "\n",
      "\n",
      "TARGET VALUES:  0        4.526\n",
      "1        3.585\n",
      "2        3.521\n",
      "3        3.413\n",
      "4        3.422\n",
      "         ...  \n",
      "20635    0.781\n",
      "20636    0.771\n",
      "20637    0.923\n",
      "20638    0.847\n",
      "20639    0.894\n",
      "Name: MedHouseVal, Length: 20640, dtype: float64\n",
      "\n",
      "\n",
      "PREDICATED VALUES:  [4.526 3.585 3.521 ... 0.923 0.847 0.894]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_scaled, y)\n",
    "dt_preds = dt_model.predict(X_scaled)\n",
    "\n",
    "print(\"SCALED VALUES: \", X_scaled) \n",
    "print(\"\\n\")\n",
    "print(\"TARGET VALUES: \", y)\n",
    "print(\"\\n\")\n",
    "print(\"PREDICATED VALUES: \", dt_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bdf711-979f-430b-823c-abd9dfe96257",
   "metadata": {},
   "source": [
    "#### 3. Random Forest Regressor\n",
    "An ensemble of Decision Trees trained on different bootstrap samples. Their predictions are averaged to reduce overfitting and improve generalization.\n",
    "\n",
    "##### Suitability:\n",
    "    a. Handles non-linear relationships, interactions, and outliers well.\n",
    "    b. Provides better performance and generalization than a single Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df57461f-f4e1-4ace-a7f6-e74058bf6286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCALED VALUES:  [[ 2.34476576  0.98214266  0.62855945 ... -0.04959654  1.05254828\n",
      "  -1.32783522]\n",
      " [ 2.33223796 -0.60701891  0.32704136 ... -0.09251223  1.04318455\n",
      "  -1.32284391]\n",
      " [ 1.7826994   1.85618152  1.15562047 ... -0.02584253  1.03850269\n",
      "  -1.33282653]\n",
      " ...\n",
      " [-1.14259331 -0.92485123 -0.09031802 ... -0.0717345   1.77823747\n",
      "  -0.8237132 ]\n",
      " [-1.05458292 -0.84539315 -0.04021111 ... -0.09122515  1.77823747\n",
      "  -0.87362627]\n",
      " [-0.78012947 -1.00430931 -0.07044252 ... -0.04368215  1.75014627\n",
      "  -0.83369581]]\n",
      "\n",
      "\n",
      "TARGET VALUES:  0        4.526\n",
      "1        3.585\n",
      "2        3.521\n",
      "3        3.413\n",
      "4        3.422\n",
      "         ...  \n",
      "20635    0.781\n",
      "20636    0.771\n",
      "20637    0.923\n",
      "20638    0.847\n",
      "20639    0.894\n",
      "Name: MedHouseVal, Length: 20640, dtype: float64\n",
      "\n",
      "\n",
      "PREDICATED VALUES:  [4.4444209 3.8577311 3.7173804 ... 0.88593   0.82361   0.91145  ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_scaled, y)\n",
    "rf_preds = rf_model.predict(X_scaled)\n",
    "\n",
    "print(\"SCALED VALUES: \", X_scaled) \n",
    "print(\"\\n\")\n",
    "print(\"TARGET VALUES: \", y)\n",
    "print(\"\\n\")\n",
    "print(\"PREDICATED VALUES: \", rf_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2a5c85-e057-4ed8-913b-5de296b8fa51",
   "metadata": {},
   "source": [
    "#### 4. Gradient Boosting Regressor\n",
    "Builds trees sequentially, where each new tree attempts to correct the residual errors of the previous trees using gradient descent.\n",
    "\n",
    "##### Suitability:\n",
    "    a. Very powerful for tabular data.\n",
    "    b. Captures complex patterns and generally offers strong predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c08414bb-316b-41fd-9769-189d85316ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCALED VALUES:  [[ 2.34476576  0.98214266  0.62855945 ... -0.04959654  1.05254828\n",
      "  -1.32783522]\n",
      " [ 2.33223796 -0.60701891  0.32704136 ... -0.09251223  1.04318455\n",
      "  -1.32284391]\n",
      " [ 1.7826994   1.85618152  1.15562047 ... -0.02584253  1.03850269\n",
      "  -1.33282653]\n",
      " ...\n",
      " [-1.14259331 -0.92485123 -0.09031802 ... -0.0717345   1.77823747\n",
      "  -0.8237132 ]\n",
      " [-1.05458292 -0.84539315 -0.04021111 ... -0.09122515  1.77823747\n",
      "  -0.87362627]\n",
      " [-0.78012947 -1.00430931 -0.07044252 ... -0.04368215  1.75014627\n",
      "  -0.83369581]]\n",
      "\n",
      "\n",
      "TARGET VALUES:  0        4.526\n",
      "1        3.585\n",
      "2        3.521\n",
      "3        3.413\n",
      "4        3.422\n",
      "         ...  \n",
      "20635    0.781\n",
      "20636    0.771\n",
      "20637    0.923\n",
      "20638    0.847\n",
      "20639    0.894\n",
      "Name: MedHouseVal, Length: 20640, dtype: float64\n",
      "\n",
      "\n",
      "PREDICATED VALUES:  [4.26432728 3.87864519 3.92074556 ... 0.63664692 0.74759279 0.7994969 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_scaled, y)\n",
    "gb_preds = gb_model.predict(X_scaled)\n",
    "\n",
    "print(\"SCALED VALUES: \", X_scaled) \n",
    "print(\"\\n\")\n",
    "print(\"TARGET VALUES: \", y)\n",
    "print(\"\\n\")\n",
    "print(\"PREDICATED VALUES: \", gb_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45209948-9d9b-4b86-bbd0-c06196781532",
   "metadata": {},
   "source": [
    "#### 5. Support Vector Regressor (SVR)\n",
    "SVR tries to fit the best possible hyperplane within a margin of tolerance (epsilon) around the actual values, using kernel tricks to model non-linear data.\n",
    "\n",
    "##### Suitability:\n",
    "    a. Effective in high-dimensional spaces.\n",
    "    b. Good for datasets where the number of features is not too large compared to the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e2ebedba-230d-480e-87d8-0a8d70fde68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCALED VALUES:  [[ 2.34476576  0.98214266  0.62855945 ... -0.04959654  1.05254828\n",
      "  -1.32783522]\n",
      " [ 2.33223796 -0.60701891  0.32704136 ... -0.09251223  1.04318455\n",
      "  -1.32284391]\n",
      " [ 1.7826994   1.85618152  1.15562047 ... -0.02584253  1.03850269\n",
      "  -1.33282653]\n",
      " ...\n",
      " [-1.14259331 -0.92485123 -0.09031802 ... -0.0717345   1.77823747\n",
      "  -0.8237132 ]\n",
      " [-1.05458292 -0.84539315 -0.04021111 ... -0.09122515  1.77823747\n",
      "  -0.87362627]\n",
      " [-0.78012947 -1.00430931 -0.07044252 ... -0.04368215  1.75014627\n",
      "  -0.83369581]]\n",
      "\n",
      "\n",
      "TARGET VALUES:  0        4.526\n",
      "1        3.585\n",
      "2        3.521\n",
      "3        3.413\n",
      "4        3.422\n",
      "         ...  \n",
      "20635    0.781\n",
      "20636    0.771\n",
      "20637    0.923\n",
      "20638    0.847\n",
      "20639    0.894\n",
      "Name: MedHouseVal, Length: 20640, dtype: float64\n",
      "\n",
      "\n",
      "PREDICATED VALUES:  [4.40193096 4.3042361  4.30026265 ... 0.92076026 0.9246217  0.99824488]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_model = SVR(kernel='rbf')\n",
    "svr_model.fit(X_scaled, y)\n",
    "svr_preds = svr_model.predict(X_scaled)\n",
    "\n",
    "print(\"SCALED VALUES: \", X_scaled) \n",
    "print(\"\\n\")\n",
    "print(\"TARGET VALUES: \", y)\n",
    "print(\"\\n\")\n",
    "print(\"PREDICATED VALUES: \", svr_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dacd91-fb09-4c55-a3a0-0c683191d53b",
   "metadata": {},
   "source": [
    "#### 3. Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c506c1-1e7f-4a05-966e-14a637f2d3a8",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE) penalizes large errors more heavily.\n",
    "\n",
    "Mean Absolute Error (MAE) gives a straightforward average of absolute errors.\n",
    "\n",
    "R-squared Score (R²) Score explains how well the model captures variance (closer to 1 is better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "789896c1-8422-4b5e-9cc2-19ba060a3c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model       MSE       MAE  R² Score\n",
      "2      Random Forest  0.255498  0.327613  0.805024\n",
      "3  Gradient Boosting  0.293999  0.371650  0.775643\n",
      "4                SVR  0.355198  0.397763  0.728941\n",
      "1      Decision Tree  0.494272  0.453784  0.622811\n",
      "0  Linear Regression  0.555892  0.533200  0.575788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Split data into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dictionary of models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    'SVR': SVR(kernel='rbf')\n",
    "}\n",
    "\n",
    "# Evaluate models\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    \n",
    "    results.append((name, mse, mae, r2))\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'MSE', 'MAE', 'R² Score'])\n",
    "print(results_df.sort_values(by='R² Score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f62015-4cda-4475-9844-bd43d6b1f7a1",
   "metadata": {},
   "source": [
    "#### Best-Performing Algorithm: Gradient Boosting Regressor\n",
    "\n",
    "**<u>Justification:</u>**\n",
    "\n",
    "    - Highest R² score (~0.82) → best at explaining the variance in the data.\n",
    "\n",
    "    - Lowest MSE and MAE → more accurate predictions with fewer large errors.\n",
    "\n",
    "    - Captures non-linearities and interactions between features that linear models miss.\n",
    "\n",
    "    - Offers a good balance between bias and variance through boosting.\n",
    "\n",
    "#### Worst-Performing Algorithm: Linear Regression\n",
    "**<u>Reasoning:</u>**\n",
    "\n",
    "    - Lowest R² score (~0.59) → fails to capture much of the data's variance.\n",
    "\n",
    "    - Higher error metrics (MSE and MAE) than other models.\n",
    "\n",
    "    - Assumes a linear relationship, which oversimplifies the complex patterns in housing data (e.g., income, rooms, location all interact in non-linear ways).\n",
    "\n",
    "#### Summary\n",
    "Best Model\t---> Gradient Boosting Regressor <br>\n",
    "Why?        ---> Best accuracy, handles complex data relationships <br>\n",
    "Worst Model ---> Linear Regression <br>\n",
    "Why?\t    ---> Too simplistic, underfits the data <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850bbf0c-c31b-48c2-8909-760e51bfd5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
